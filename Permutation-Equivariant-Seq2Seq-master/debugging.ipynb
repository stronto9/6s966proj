{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from perm_equivariant_seq2seq.equivariant_models import EquiSeq2Seq\n",
    "from perm_equivariant_seq2seq.data_utils import get_scan_split, get_equivariant_scan_languages\n",
    "from perm_equivariant_seq2seq.symmetry_groups import get_permutation_equivariance, CircularShift\n",
    "from perm_equivariant_seq2seq.utils import tensors_from_pair, tensor_from_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pairs, test_pairs = get_scan_split(split='add_jump')\n",
    "in_equivariances = ['jump', 'run', 'walk', 'look']\n",
    "out_equivariances = ['JUMP', 'RUN', 'WALK', 'LOOK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equivariant_commands, equivariant_actions = get_equivariant_scan_languages(pairs=train_pairs, input_equivariances=in_equivariances, output_equivariances=out_equivariances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_symmetry_group = get_permutation_equivariance(equivariant_commands)\n",
    "output_symmetry_group = get_permutation_equivariance(equivariant_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure that these groups are actually groups\n",
    "# 1. check identity is correct\n",
    "# 2. check inverses is correct\n",
    "# 3. check closure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_identity(perm_group):\n",
    "    eye = perm_group.e\n",
    "    assert torch.equal(perm_group.index2mat[0], eye), \"indexing of identity is incorrect\"\n",
    "    for idx in perm_group.index2mat:\n",
    "        assert torch.equal(eye @ perm_group.index2mat[idx], perm_group.index2mat[idx]), \"identity behavior incorrect\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_inverses(perm_group):\n",
    "    # check index2mat, index2inverse, and index2inverse_indices are correct\n",
    "    # check that they are actually inverses\n",
    "    assert len(perm_group.index2mat) == len(perm_group.index2inverse), \"dictionary sizes inconsistent\"\n",
    "    assert len(perm_group.index2inverse) == len(perm_group.index2inverse_indices), \"dictionary sizes inconsistent part 2\"\n",
    "    for idx in perm_group.index2mat:\n",
    "        # print(\"--- \", idx)\n",
    "        inv = perm_group.index2inverse[idx]\n",
    "        inv_prods = perm_group.index2inverse_indices[idx]\n",
    "        # print(inv)\n",
    "        # print(inv_prods)\n",
    "        for idy in perm_group.index2mat:\n",
    "            # print(\"------ \", idy)\n",
    "            # print(inv @ perm_group.index2mat[idy])\n",
    "            # print(perm_group.index2mat[inv_prods[idy].item()])\n",
    "            # print(f\"inv @ mat shape: {(inv @ perm_group.index2mat[idy]).shape}\")\n",
    "            # print(f\"inv_prods: {(perm_group.index2mat[inv_prods[idy].item()]).shape}\")\n",
    "            assert torch.isclose(inv @ perm_group.index2mat[idy], perm_group.index2mat[inv_prods[idy].item()]).all(), \"index2inverses_indices book-keeping incorrect\"\n",
    "        assert torch.isclose(inv @ perm_group.index2mat[idx], perm_group.e).all(), \"inverse behavior incorrect\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_closure(perm_group):\n",
    "    for idx in perm_group.index2mat:\n",
    "        for idy in perm_group.index2mat:\n",
    "            prod = perm_group.index2mat[idx] @ perm_group.index2mat[idy]\n",
    "            in_group = False\n",
    "            for idz in perm_group.index2mat:\n",
    "                if torch.isclose(prod, perm_group.index2mat[idz]).all():\n",
    "                    in_group = True\n",
    "                    break\n",
    "            assert in_group, \"product of elements not in group\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test with cyclic shift\n",
    "cyclic = CircularShift(num_letters=equivariant_commands.n_words,\n",
    "                         num_equivariant=equivariant_commands.num_equivariant_words,\n",
    "                         first_equivariant=equivariant_commands.num_fixed_words + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_group(gp):\n",
    "    check_identity(gp)\n",
    "    check_inverses(gp)\n",
    "    check_closure(gp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_group(cyclic)\n",
    "test_group(input_symmetry_group)\n",
    "test_group(output_symmetry_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing einsum code\n",
    "ipt = torch.randn(1, 3, 2) # batch x |G| x K\n",
    "conv_filter = torch.randn(3, 3, 2, 2) # |G| x |G| x K x K\n",
    "# expect output to have shape: batch x |G| x K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_ein = torch.einsum(\"bhk,ghkl->bgl\", ipt, conv_filter)\n",
    "print(use_ein)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip = ipt[:, None, ..., None]\n",
    "conv_fil = conv_filter[None, ...]\n",
    "old_ver = (ip * conv_fil).sum(2).sum(2)\n",
    "\n",
    "print(old_ver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.allclose(use_ein, old_ver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
